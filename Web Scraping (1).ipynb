{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /srv/conda/lib/python3.6/site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /srv/conda/lib/python3.6/site-packages (from beautifulsoup4) (1.7.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Establish connection,downloading the html page & storing it in a local variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import urlopen as ureq\n",
    "\n",
    "my_url = \"https://www.flipkart.com/search?q=xiaomi+redmi+note+5+pro&sid=tyy%2C4io&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_0_12&otracker1=AS_QueryStore_OrganicAutoSuggest_0_12&as-pos=0&as-type=RECENT&as-searchtext=xiaomi%20redmi\"\n",
    "\n",
    "uclient = ureq(my_url) #to open up the connection and save it in uclient\n",
    "page_html = uclient.read() #reads the data & stores it in this variale\n",
    "uclient.close() #close the terminal\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "type(page_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parsing the HTMl page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "### containers variable contain all the data in the main div element wchich contains the name, price & rating of the product\n",
    "containers = page_soup.findAll(\"div\", {\"class\": \"_3O0U0u\"})\n",
    "print(len(containers)) # This tells us that there are 15 elements in this webpage which has a div with class name \"bsgxx2 col-12-12\"\n",
    "#Containers is an array of 15 elements with div class bhgxx2 col-12-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(soup.prettify(containers[0])) #this will beautifully present the contents of the very first element of the container tag\n",
    "print(soup.prettify(containers[0]))\n",
    "container = containers[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data of a particular div element\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the name of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redmi Note 5 Pro (Blue, 64 GB)\n"
     ]
    }
   ],
   "source": [
    "# say we want to print the name of product\n",
    "# From inspecting the html file of the above output we find that the name of the product is\n",
    "# this html document contains a main div class within which there are several div classes\n",
    "# but we are interested in finding a div class which has an img tag and that too with an alt attribute\n",
    "# div.img[\"alt\"] contains the title of the product\n",
    "# attributes are written in square brckts\n",
    "\n",
    "# name = container.div.img[\"alt\"]\n",
    "# print(name)\n",
    "\n",
    "# The above is one way of doing this\n",
    "\n",
    "# Second method\n",
    "\n",
    "name = page_soup.findAll(\"div\", {\"class\" : \"_3wU53n\"})\n",
    "#print(name[0])\n",
    "print(name[2].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the price of the product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"_1vC4OE _2rQ-NK\">₹12,999</div>\n",
      "₹12,999\n"
     ]
    }
   ],
   "source": [
    "# lets scrap the price\n",
    "# from inspecting we find the location of the div which contains the price\n",
    "# we find that all the prices are listed under a div with a common class name\n",
    "# so again we save all this info inside an array like we did with container\n",
    "\n",
    "price = page_soup.findAll(\"div\", {\"class\" : \"_1vC4OE _2rQ-NK\"})\n",
    "\n",
    "# Now we print the prie of the first mobile\n",
    "\n",
    "print(price[0])\n",
    "# On doing this we find that it prints the entire div tag\n",
    "# So we take just the text part of the div, since the price is not under any html tag, its a simple text\n",
    "\n",
    "print(price[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On inspection we find the location of the rating tag\n",
    "rating = page_soup.findAll(\"div\", {\"class\": \"hGSR34 _2beYZw\"})\n",
    "print(len(rating))\n",
    "print(rating[0])\n",
    "print(rating[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a csv file and storing the name of the product, price & rating of all the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"product.csv\"\n",
    "f = open(filename, \"w\")\n",
    "\n",
    "headers = \"Product_Name,Price,Rating\\n\"\n",
    "f.write(headers)\n",
    "# The above line will create the headers below which the details shall be listed\n",
    "\n",
    "# Now we shall loop through the containers array\n",
    "# and shall store the detals accordingly\n",
    "\n",
    "k=0 # for selecting the 1st elemet price, then 2nd element price, then 3rd & so on\n",
    "\n",
    "for container in containers:\n",
    "    # product_name = container.div.img[\"alt\"] --> This is first method to fetch the product name\n",
    "    name_div = page_soup.findAll(\"div\", {\"class\" : \"_3wU53n\"})\n",
    "    product_name = name_div[k].text\n",
    "    \n",
    "    prices_div = page_soup.findAll(\"div\", {\"class\" : \"_1vC4OE _2rQ-NK\"}) # This will return the html tag . From this I need to extract the text which is the price\n",
    "    prices = prices_div[k].text.strip() # Strip function removes any unnecessary commas, spaces etc\n",
    "    \n",
    "    ratings_div = page_soup.findAll(\"div\", {\"class\": \"hGSR34 _2beYZw\"})\n",
    "    ratings = ratings_div[k].text\n",
    "    \n",
    "    k = k+1\n",
    "    \n",
    "    # print(\"Product_name \" + product_name)\n",
    "    # print(\"Price \" + prices)\n",
    "    # print(\"Ratings \" + ratings)\n",
    "    \n",
    "    # Now say we want to remove the rupee sumbol and i want just the price\n",
    "    # Or say there are other text involved with the price (which is not here) then we can furthur use the split, replace and sometimes join function to get the text we want\n",
    "    \n",
    "    # Lets now write this in our csv file\n",
    "    \n",
    "    product_split = product_name.split(\",\")\n",
    "    new_product_name = product_split[0] + product_split[1]\n",
    "\n",
    "    f.write(new_product_name + \",\" + prices + \",\" + ratings + \"\\n\")\n",
    "\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
